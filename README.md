# StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pretrained StyleGAN

[paper](https://arxiv.org/pdf/2203.04036.pdf) | [project website](https://FeiiYin.github.io/StyleHEAT/)

  
<img src="docs/images/402_poster.jpg" width="800px"/> 

 
## Abstract

We investigate the latent feature space of a pre-trained StyleGAN and discover some excellent spatial transformation properties. 
Based on the observation, we propose a novel unified framework based on a pre-trained StyleGAN that enables a set of powerful functionalities, 
*i.e.,* *high-resolution video generation, disentangled control by driving video or audio, and flexible face editing*. 

## Code Coming Soon!

## Citation
If you find this work useful for your research, please cite:

``` 
@article{2203.04036,
      author = {Yin, Fei and Zhang, Yong and Cun, Xiaodong and Cao, Mingdeng and Fan, Yanbo and Wang, Xuan and Bai, Qingyan and Wu, Baoyuan and Wang, Jue and Yang, Yujiu},
      title = {StyleHEAT: One-Shot High-Resolution Editable Talking Face Generation via Pre-trained StyleGAN}, 
      journal = {arxiv:2203.04036},  
      year = {2022}
}
```

## Acknowledgement
Thanks to 
[StyleGAN-2](https://github.com/NVlabs/stylegan2), 
[PIRenderer](https://github.com/RenYurui/PIRender), 
[HFGI](https://github.com/Tengfei-Wang/HFGI), 
[BaberShop](https://github.com/ZPdesu/Barbershop), 
[GFP-GAN](https://github.com/TencentARC/GFPGAN), 
[Pixel2Style2Pixel](https://github.com/eladrich/pixel2style2pixel) 
for sharing their code.